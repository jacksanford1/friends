{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Training the model\n\nWe utilize Kaggle's free GPU to train a model with 1 convolutional layer, 2 GRU layers and a dense layer. Because there is so much laughter in the show, we are able to use accuracy as our metric to optimize. However, we also pay close attention to precision and recall as well as F1 score. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking our data sources"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input/\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading X and y inputs (we created these in the friendsaudio notebook)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load X and Y files\nprexfolder = '/kaggle/input/friendsaudio/prex/'\npreyfolder = '/kaggle/input/friendsaudio/prey/'\n\nloadedX = np.load(prexfolder + 'prex.txt.npy')\nloadedY = np.load(preyfolder + 'prey.txt.npy')\nprint(\"Shape of X is \" + str(loadedX.shape))\nprint(\"Shape of Y is \" + str(loadedY.shape))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Getting train, dev, test sets\n\nWe split X and y into 60% train, 20% dev and 20% test sets. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting train, dev, test sets\n\nX = loadedX\ny = loadedY\n\n# splitting train (80%) and test (20%)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n\n# Taking train (80%) and removing 25% to create val (20% overall) and leaves train at 60% overall\nX_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n\nprint(\"Shape of X_train and y_train are \" + str(X_train.shape) + \", \" +  str(y_train.shape))\nprint(\"Shape of X_dev and y_dev are \" + str(X_dev.shape) + \", \" +  str(y_dev.shape))\nprint(\"Shape of X_test and y_test are \" + str(X_test.shape) + \", \" +  str(y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\nfrom keras.models import Model, load_model, Sequential\nfrom keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\nfrom keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\nfrom keras.optimizers import Adam\nfrom keras.metrics import Precision, Recall","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define model\n\nHere we define our model and some hyperparameters. Did a lot of guess-and-check work with different ordering, different hyperparameters and different layers. This model turned out to be the best out of all the models tested. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(input_shape):\n    \n    X_input = Input(shape = input_shape)\n    \n    # Convolution layer\n    X = Conv1D(filters=256,kernel_size=15,strides=1)(X_input)\n    X = BatchNormalization()(X)\n    X = output_x = Activation(\"relu\")(X)\n    X = Dropout(rate=0.8)(X)\n    \n    # GRU Layer 1\n    X = GRU(units=256, return_sequences = True)(X)\n    X = Dropout(rate=0.8)(X)\n    X = BatchNormalization()(X)\n    \n    # GRU Layer 2\n    X = GRU(units=256, return_sequences = True)(X)\n    X = Dropout(rate=0.8)(X)\n    X = BatchNormalization()(X)\n    X = Dropout(rate=0.8)(X)\n    \n    # Time-Distributed Dense Layer with Sigmoid\n    X = TimeDistributed(Dense(1, activation = \"sigmoid\"))(X)\n    \n    model = Model(inputs = X_input, outputs = X)\n    \n    return model\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Telling the model what the input shape of the data will be."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model(input_shape = (X_train.shape[1], X_train.shape[2]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Making sure we are getting the right input/output shapes we expect in every layer."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using Adam for gradient descent optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01)\nmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\", Precision(), Recall()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training the model\n\nFor our final model weights, we trained for 100 epochs (took around 5-6 hours). But for testing different layers and hyperparameters, 15 epochs was plenty to give a sense of how a model would perform. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train model\nmodel.fit(X_train, y_train, batch_size = 32, epochs = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dev set metrics\n\nAccuracy was the metric we optimized for. But it was helpful to see precision and recall to understand whether we were missing a lot of \"true\" laughter or labeling things that weren't laughter as laughter.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test on dev set\nloss, acc, prec, recall = model.evaluate(X_dev, y_dev)\nF1 = 2 * ((prec * recall) / (prec + recall))\nprint(\"Dev set accuracy = \", acc)\nprint(\"Dev set precision = \", prec)\nprint(\"Dev set recall = \", recall)\nprint(\"Dev set F1 = \", F1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving down model weights for predicting in another notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"savefolder = '/kaggle/working/'\n\nmodel.save_weights(savefolder + 'rawaudiomodelweights.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Looking at specific dev set examples\n\nIt was helpful to look at specific 10-second clip examples to see exactly how the model was performing. Early on, it was getting all the laughter correct but it was labeling lots of things that weren't laughter as well. "},{"metadata":{"trusted":true},"cell_type":"code","source":"numpick = 1\nexample = X_dev[numpick]\nexample = np.expand_dims(example, axis=0)\npreds = model.predict(example)\nprobs = preds[0, :, 0]\n\n# probabilities graph\nplt.subplot(1, 1, 1)\nplt.plot(probs)\nplt.ylabel('probability')\nplt.show()\n\nbinary = np.where(probs > 0.5, 1, 0)\n\n# binary preds graph\nplt.subplot(1, 1, 1)\nplt.plot(binary)\nplt.ylabel('binary preds')\nplt.show()\n\nactual = y_dev[numpick]\n\n# actuals graph\nplt.subplot(1, 1, 1)\nplt.plot(actual)\nplt.ylabel('actuals')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Looking at specific examples in more depth\n\nThis code allowed us to see the spectrogram alongside the labeled laughter. It became clear that when we inverted the audio track, it was much easier for the model to correctly label laughter. It was also much easier for the human eye to see laughter instances with an inverted audio track."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.io import wavfile\nimport IPython\n\ntestclipfolder = '/kaggle/input/randomtestclips/'\ncliplist = os.listdir(testclipfolder)\n\ntestnum = 7\n\nfor i, clip in enumerate(cliplist):\n    if i == testnum:\n        filepath = testclipfolder + clip\n        IPython.display.display(IPython.display.Audio(filepath))\n        \n        FS, data = wavfile.read(filepath)\n        pxx, freqs, bins, im = plt.specgram(data, Fs=FS, NFFT=512, noverlap=0)\n        plt.show()\n        pxxtransposed = pxx.T\n        cliptopredict = np.expand_dims(pxxtransposed, axis=0)\n        testpreds = model.predict(cliptopredict)\n        testprobs = testpreds[0, :, 0]\n\n        # probabilities graph\n        plt.subplot(2, 1, 2)\n        plt.plot(testprobs)\n        plt.ylabel('something')\n        plt.show()\n\n        binary = np.where(testprobs > 0.5, 1, 0)\n\n        # binary preds graph\n        plt.subplot(2, 1, 2)\n        plt.plot(binary)\n        plt.ylabel('test binary preds')\n        plt.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}