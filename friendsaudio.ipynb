{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Audio Preprocessing\n\nTaking in the raw audio files for 20 episodes, processing and setting equal to X. Then taking the \"labels\" for laughter that I hand-made for each episode, and setting them equal to y. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pydub","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from pydub import AudioSegment\nimport os\nfrom scipy.io import wavfile\nimport matplotlib.pyplot as plt\nimport operator\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport shutil","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking kaggle notebook folder for input data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Deciding how long each clip should be, how many timesteps it should be split into, and how much overlap each clip should have. ","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# predtimesteps is dictated by model\npredtimesteps = 847\ncliplen = 10000\nlag = 0 # this will dictate overlap necessary\noverlap = round(((cliplen / predtimesteps) * lag) + 1) # rounding up to nearest ms here\nprint(\"overlap in ms is \" + str(overlap))\nprint(\"length of each timestep in ms is \" + str(cliplen / predtimesteps))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Defining folders","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"audiofolder = '/kaggle/input/labeledepisodes/'\nlaughlabelsfolder = '/kaggle/input/laughlabels/'\nclipsfolder = '/kaggle/working/clips/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating 10-sec wav clips out of episodes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"if os.path.exists(clipsfolder):\n    # deletes clips folder and all clips inside\n    shutil.rmtree(clipsfolder)\n    # makes new empty clips folder\n    os.makedirs(clipsfolder)\nelse:\n    os.makedirs(clipsfolder)\n\nfor filename in os.listdir(audiofolder):\n    if not filename.startswith('.'):\n        season = filename[9:11]\n        episode = filename[12:14]\n        filepath = audiofolder + filename\n        file = AudioSegment.from_file(filepath)\n#         print(\"Length of file is \" + str(len(file)))\n\n        startcut = 0\n        endcut = startcut + cliplen\n        count = 1\n\n        while startcut < len(file):\n            #create clip here\n            clip = file[startcut:endcut]\n            if len(clip) < cliplen:\n                break\n            else:\n                clip.export(clipsfolder + \"s\" + str(season) + \"e\" + str(episode) + \"n\" + str(count) + \"beg\" + str(startcut) + \"end\" + str(endcut) + \".wav\", format=\"wav\")\n\n\n\n#             print(\"clip num is \" + str(count))\n#             print(\"clip start is \" + str(startcut))\n#             print(\"clip end is \" + str(endcut))\n#             print(\"clip len is \" + str(len(clip)))\n            #increment values for next clip\n            startcut += (cliplen - overlap)\n            endcut = min(startcut + cliplen, len(file))\n            count += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sorting all clips by episode and beginning timestep","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"listtosort = []\n\nfor filename in os.listdir(clipsfolder):\n    if not filename.startswith('.'):\n        season = int(filename[1:3])\n        episode = int(filename[4:6])\n        findbegstart = filename.find(\"beg\")\n        findendstart = filename.find(\"end\")\n        findendend = filename.find(\".\")\n        begtimestart = findbegstart + 3\n        endtimestart = findendstart + 3\n        begtime = int(filename[begtimestart:findendstart])\n        endtime = int(filename[endtimestart:findendend])\n        listtosort.append([season, episode, begtime, endtime, filename])\n\n\nsortedclips = sorted(listtosort, key = operator.itemgetter(0, 1, 2))\n# print(sortedclips)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing X\n\nTurning 10-second clip into spectrogram data. Splitting clip into defined number of timesteps and frequencies. Getting each clip into the right shape to be fed into the model. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating X numpy array of shape (number of clips, number of frequencies, number of spectrogram timesteps)\n\ncount = 0\n\nfor info in sortedclips:\n    clipfilename = info[4]\n    clipfilepath = clipsfolder + clipfilename\n    FS, data = wavfile.read(clipfilepath) # read wav file\n    channelcount = data.ndim\n#     print(\"Number of channels is \" + str(data.ndim))\n    if channelcount == 1:\n        pxx, freqs, bins, im = plt.specgram(data, Fs=FS, NFFT=512, noverlap=0)  # building plot and spectrogram\n    elif channelcount == 2:\n        pxx, freqs, bins, im = plt.specgram(data[:,0], Fs=FS, NFFT=512, noverlap=0)  # building plot and spectrogram\n    Tx = pxx.shape[1] # represents number of time steps in spectrogram\n    n_freq = pxx.shape[0] # represents number of frequencies in spectrogram\n    pxxtransposed = pxx.T\n    if count == 40:\n        print(\"file duration is \" + str(len(data) / float(FS)))\n        print(\"filename is \" + str(clipfilename))\n        print(\"number of channels is \" + str(data.ndim)) # 1 channel now because we are merging in stereo\n        print(\"num of time steps in spectrogram is \" + str(Tx))\n        print(\"num of frequencies in spectrogram is \" + str(n_freq))\n        print(\"shape of pxxtransposed is \" + str(pxxtransposed.shape))\n        plt.show() # plot the spectrogram\n    if count == 0:\n        preX = np.zeros((len(sortedclips), Tx, n_freq))\n        print(\"preX zeros shape is \" + str(preX.shape))\n    os.remove(clipfilepath)\n    preX[count] = pxxtransposed\n#     spectdata.append(pxxtransposed)\n#     np.save(xfolder + str(count) + '.txt', pxxtransposed)\n    count += 1\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing laugh labels\n\n* Creating dictionary of laugh labels for hand-labeled episodes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"labeldict = {}\n\nfor filename in os.listdir(laughlabelsfolder):\n    if not filename.startswith('.'):\n        season = filename[0:2]\n        episode = filename[2:4]\n        labeldict[season + episode] = []\n        htmlpath = laughlabelsfolder + filename\n        with open(htmlpath) as f:\n            for line in f:\n                if '\\\\' not in line:\n                    # converting to ms\n#                     print(season, episode)\n#                     print(line)\n                    pair = [float(i) * 1000 for i in line.split()]\n                    labeldict[season + episode].append(pair)\n                else:\n                    continue\nprint(labeldict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating Y numpy array of shape (number of clips, number of predicted timesteps, 1)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, info in enumerate(sortedclips):\n    season = info[0]\n    dictseason = str(season).zfill(2)\n    episode = info[1]\n    dictepisode = str(episode).zfill(2)\n    begtime = info[2]\n    endtime = info[3]\n    workinglabels = labeldict[dictseason + dictepisode]\n    cliplabels = []\n    increment = (endtime - begtime) / predtimesteps\n    for count in range(predtimesteps): # range is from 0 to end - 1 for example\n        # this skips t-0 as a timestep but includes last possible timestep (t-1000 if there are 1000 timesteps)\n        timestep = begtime + increment + (count * increment)\n        timesteplabel = 0\n        for pair in workinglabels:\n            if pair[0] <= timestep <= pair[1]:\n                timesteplabel = 1\n        cliplabels.append(timesteplabel)\n#     print(\"Length of cliplabels is \" + str(len(cliplabels)))\n    sortedclips[i].append(cliplabels)\nprint(sortedclips)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Add lag to y-values (if any)\n\nOriginal thought was that some lag between the laughter and the laughter label could help the model learn faster. This didn't seem to be the case so we are not using any lag. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sortedlagclips = []\n\nfor info in sortedclips:\n    beforelag = info[5]\n    afterlag = beforelag[:-lag or None]\n    pos = 0\n    value = 0\n    for i in range(lag):\n        afterlag.insert(pos, value)\n    sortedlagclips.append([info[0], info[1], info[2], info[3], info[4], afterlag])\nprint(sortedlagclips)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create y numpy array to be fed to model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preYlist = []\n\nfor info in sortedlagclips:\n    labels = info[5]\n    preYlist.append(labels)\npreY = np.stack(preYlist, axis=0)\npreY = np.expand_dims(preY, axis=2)\nprint(preY.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving X and y locally in Kaggle (to be manipulated in the next notebook)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prexfolder = '/kaggle/working/prex/'\npreyfolder = '/kaggle/working/prey/'\n\nprint(\"shape of preX is \" + str(preX.shape))\nprint(\"shape of preY is \" + str(preY.shape))\n\nif os.path.exists(clipsfolder):\n    # deletes clips folder and all clips inside\n    shutil.rmtree(clipsfolder)\nif os.path.exists(prexfolder):\n    shutil.rmtree(prexfolder)\nif os.path.exists(preyfolder):\n    shutil.rmtree(preyfolder)\n\nos.makedirs(prexfolder)\nos.makedirs(preyfolder)\n\nnp.save(prexfolder + 'prex.txt', preX)\nnp.save(preyfolder + 'prey.txt', preY)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}