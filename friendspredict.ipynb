{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Our Trained ML Model to Predict Laughter\n",
    "\n",
    "In an earlier notebook, we trained our model to identify laughter using a training set of ~20 episodes (each episode is around ~22 mins) which is about 7 hours of training data split into 10-second increments.\n",
    "\n",
    "In this notebook, we load all remaining 214 episodes of friends and predict the exact time ranges of laughter for each episode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import numpy as np\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deciding clip length and overlap between clips\n",
    "\n",
    "We use 10 second clips just like we used in training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predtimesteps is dictated by trained model\n",
    "predtimesteps = 847\n",
    "cliplen = 10000\n",
    "lag = 0 # this will dictate overlap necessary\n",
    "overlap = 0 # old formula = round(((cliplen / predtimesteps) * lag) + 1) # rounding up to nearest ms here\n",
    "timesteplen = cliplen / predtimesteps\n",
    "print(\"overlap in ms is \" + str(overlap))\n",
    "print(\"length of each timestep in ms is \" + str(timesteplen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating 10-second clips\n",
    "\n",
    "We take in the preprocessed audio files from each episode (~22 mins each) and slice them into 10-second audio clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 10-sec wav clips out of episodes\n",
    "audiofolder = '/Users/Jack/Developer/friends/allaudio/'\n",
    "seasonfilter = 5\n",
    "\n",
    "for filename in os.listdir(audiofolder):\n",
    "    if not filename.startswith('.'):\n",
    "        season = filename[9:11]\n",
    "        if int(season) == seasonfilter:\n",
    "            episode = filename[12:14]\n",
    "            filepath = audiofolder + filename\n",
    "            file = AudioSegment.from_file(filepath)\n",
    "    #         print(\"Length of file is \" + str(len(file)))\n",
    "\n",
    "            startcut = 0\n",
    "            endcut = startcut + cliplen\n",
    "            count = 1\n",
    "\n",
    "            while startcut < len(file):\n",
    "                #create clip here\n",
    "                clip = file[startcut:endcut]\n",
    "                if len(clip) < cliplen:\n",
    "                    break\n",
    "                else:\n",
    "                    clip.export(\"/Users/Jack/Developer/friends/clips/s\" + str(season) + \"e\" + str(episode) + \"n\" + str(count) + \"beg\" + str(startcut) + \"end\" + str(endcut) + \".wav\", format=\"wav\")\n",
    "\n",
    "\n",
    "\n",
    "    #             print(\"clip num is \" + str(count))\n",
    "    #             print(\"clip start is \" + str(startcut))\n",
    "    #             print(\"clip end is \" + str(endcut))\n",
    "    #             print(\"clip len is \" + str(len(clip)))\n",
    "                #increment values for next clip\n",
    "                startcut += (cliplen - overlap)\n",
    "                endcut = min(startcut + cliplen, len(file))\n",
    "                count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting the clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master sort\n",
    "\n",
    "listtosort = []\n",
    "clipsfolder = '/Users/Jack/Developer/friends/clips/'\n",
    "\n",
    "for filename in os.listdir(clipsfolder):\n",
    "    if not filename.startswith('.'):\n",
    "        season = int(filename[1:3])\n",
    "        if season == seasonfilter:\n",
    "            episode = int(filename[4:6])\n",
    "            findbegstart = filename.find(\"beg\")\n",
    "            findendstart = filename.find(\"end\")\n",
    "            findendend = filename.find(\".\")\n",
    "            begtimestart = findbegstart + 3\n",
    "            endtimestart = findendstart + 3\n",
    "            begtime = int(filename[begtimestart:findendstart])\n",
    "            endtime = int(filename[endtimestart:findendend])\n",
    "            listtosort.append([season, episode, begtime, endtime, filename])\n",
    "\n",
    "\n",
    "sortedclips = sorted(listtosort, key = operator.itemgetter(0, 1, 2))\n",
    "# print(sortedclips)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shaping clips into the correct form for the model\n",
    "\n",
    "We take the 10-second clips and we break the clips into 861 separate timesteps and we measure 257 unique frequency levels at each timestep. Then we package the timesteps and frequencies for each clip and create a numpy array that we can feed to our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X numpy array of shape (number of clips, number of frequencies, number of spectrogram timesteps)\n",
    "\n",
    "count = 1\n",
    "clipsfolder = '/Users/Jack/Developer/friends/clips/'\n",
    "# totalclips = len(sortedclips)\n",
    "# print(totalclips)\n",
    "spectdata = []\n",
    "\n",
    "for info in sortedclips:\n",
    "    filename = info[4]\n",
    "    filepath = clipsfolder + filename\n",
    "    FS, data = wavfile.read(filepath) # read wav file\n",
    "#     print(\"Number of channels is \" + str(data.ndim))\n",
    "    pxx, freqs, bins, im = plt.specgram(data, Fs=FS, NFFT=512, noverlap=0)  # building plot and spectrogram\n",
    "    Tx = pxx.shape[1] # represents number of time steps in spectrogram\n",
    "    n_freq = pxx.shape[0] # represents number of frequencies in spectrogram\n",
    "    pxxtransposed = pxx.T\n",
    "#     print(\"filename is \" + str(filename))\n",
    "#     print(\"Shape of pxxtransposed is \" + str(pxxtransposed.shape))\n",
    "    spectdata.append(pxxtransposed)\n",
    "    if count == 40:\n",
    "        print(\"file duration is \" + str(len(data) / float(FS)))\n",
    "        print(\"filename is \" + str(filename))\n",
    "        print(\"number of channels is \" + str(data.ndim)) # 1 channel now because we are merging in stereo\n",
    "        print(\"num of time steps in spectrogram is \" + str(Tx))\n",
    "        print(\"num of frequencies in spectrogram is \" + str(n_freq))\n",
    "#         plt.show() # plot the spectrogram\n",
    "    count += 1\n",
    "preX = np.stack(spectdata, axis=0)\n",
    "print(\"shape of preX is \" + str(preX.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We save the numpy array of clip info locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preX\n",
    "modeldatafolder = '/Users/Jack/Developer/friends/modeldata/'\n",
    "\n",
    "np.save(modeldatafolder + 'preX' + str(seasonfilter) + '.txt', preX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removed some preprocessing for preX so now we just assign as X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redefining our CNN+GRU neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "    \n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # Convolution layer\n",
    "    X = Conv1D(filters=256,kernel_size=15,strides=1)(X_input)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = output_x = Activation(\"relu\")(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    \n",
    "    # GRU Layer 1\n",
    "    X = GRU(units=256, return_sequences = True)(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    # GRU Layer 2\n",
    "    X = GRU(units=256, return_sequences = True)(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    \n",
    "    # Time-Distributed Dense Layer with Sigmoid\n",
    "    X = TimeDistributed(Dense(1, activation = \"sigmoid\"))(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining model input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(input_shape = (X.shape[1], X.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading weights from our previously trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfolder = '/Users/Jack/Developer/friends/modelweights/'\n",
    "\n",
    "model.load_weights(modelfolder + 'modelweights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Adam gradient descent optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\", Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting for all clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then predict for all clips\n",
    "rawprobs = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rawprobs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chose an 80% confidence threshold for laughter inclusion\n",
    "\n",
    "Our precision score was lower than our recall score for a long time, so I decided to be more strict on what counted as laughter. We were getting almost all \"true\" laughter instances correct, but we were including some instances that were not laughter more often, so raising the threshold would correct for this. However, I think the precision and recall scores switched slightly in the last few versions of the model training, so I probably could have lowered this back down to ~50%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any probs above 80% are counted as laughter\n",
    "probs = rawprobs[:, :, 0]\n",
    "preds = np.where(probs > 0.8, 1, 0)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing performance on some individual clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip test\n",
    "# S5E15 starts at clipnum 2100\n",
    "clipnum = 1866\n",
    "clipdata = X[clipnum]\n",
    "clipdata = np.expand_dims(clipdata, axis=0)\n",
    "preds = model.predict(clipdata)\n",
    "probs = preds[0, :, 0]\n",
    "\n",
    "# audio output\n",
    "clipsfolder = '/Users/Jack/Developer/friends/clips/'\n",
    "clipinfo = sortedclips[clipnum]\n",
    "filename = clipinfo[4]\n",
    "filepath = clipsfolder + filename\n",
    "print(filename)\n",
    "IPython.display.display(IPython.display.Audio(filepath))\n",
    "\n",
    "# probabilities graph\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(probs)\n",
    "plt.ylabel('probability')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dict with episode clip counts for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epclipcounts = {}        \n",
    "\n",
    "for i, info in enumerate(sortedclips):\n",
    "    season = info[0]\n",
    "    episode = info[1]\n",
    "    begtime = info[2]\n",
    "    endtime = info[3]\n",
    "    filename = info[4]\n",
    "    if season == seasonfilter:\n",
    "        if episode not in epclipcounts:\n",
    "            epclipcounts[episode] = 1\n",
    "        else:\n",
    "            epclipcounts[episode] += 1\n",
    "print(epclipcounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking our clip count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalclips = 0\n",
    "for ep, epcount in epclipcounts.items():\n",
    "    totalclips += epcount\n",
    "print(\"Total clips is \" + str(totalclips) + \" and should be equal to \" + str(preds.shape[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing laughter predictions for each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startpos = 0\n",
    "predsbyep = {}\n",
    "\n",
    "for ep, epcount in epclipcounts.items():\n",
    "    key = \"s\" + str(seasonfilter).zfill(2) + \"e\" + str(ep).zfill(2)\n",
    "    endpos = startpos + epcount\n",
    "    print(startpos, endpos)\n",
    "    predsbyep[key] = preds[startpos:endpos]\n",
    "    print(key, predsbyep[key].shape)\n",
    "    startpos += epcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving laughter predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to predsbyep folder\n",
    "predsbyepfolder = '/Users/Jack/Developer/friends/predsbyep/'\n",
    "\n",
    "for ep, array in predsbyep.items():\n",
    "    np.save(predsbyepfolder + ep + \".txt\", array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating final laughter ranges\n",
    "\n",
    "There are effectively two processing steps I take here in order to make the laughter ranges even more accurate. Anything under 400 milliseconds is too short to be a standalone laughter instance, so it either needs to join together with a close-by laughter instance, or it needs to be removed. Any gap of 100ms or less between two laughter instances is much to short to be meaningful, so we combine those two laughter instances into one longer laughter instance. \n",
    "\n",
    "We output a dictionary where the keys are specific episodes and the values are lists that contain pairs of start/end timestamps for laughter instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All seasons at once starting here\n",
    "laughrangesdict = {}\n",
    "minlaughlen = 400 # in ms - this decides the minimum length to be considered a laugh\n",
    "concatlaugh = 100 # in ms - this decides the maximum length in between two laughs in order to join them together\n",
    "consecsteps = int(minlaughlen / timesteplen) # min number of timesteps in a row to register as laugh\n",
    "consecnolaugh = int(concatlaugh / timesteplen) # max number of no-laugh timesteps in a row to combine two laughs\n",
    "print(\"min # of timesteps in a row to register a laugh is \" + str(consecsteps))\n",
    "print(\"max # of timesteps in a row to combine two laughs is \" + str(consecnolaugh))\n",
    "\n",
    "for filename in os.listdir(predsbyepfolder):\n",
    "    if not filename.startswith('.'):\n",
    "        season = filename[1:3]\n",
    "        episode = filename[4:6]\n",
    "#         if int(season) == seasonfilter:\n",
    "        ep = np.load(predsbyepfolder + filename)\n",
    "        flatep = ep.flatten()\n",
    "        switchingindices = []\n",
    "        # finding all indices where the value switches from the previous index (0 to 1 or 1 to 0)\n",
    "        for i, step in enumerate(flatep):\n",
    "            # starting first value at 0 no matter what\n",
    "            if i == 0:\n",
    "                flatep[i] = 0\n",
    "            # putting last value as zero so we get even number of switches no matter what\n",
    "            elif i == len(flatep) - 1:\n",
    "                flatep[i] = 0\n",
    "                # may need to switch on last value if value before was 1 (in order to keep switches even)\n",
    "                if flatep[i - 1] == 1:\n",
    "                    switchingindices.append(i)\n",
    "            # checking to see if we should switch on any given value (except first or last value handled above)\n",
    "            elif flatep[i] != flatep[i - 1]:\n",
    "                switchingindices.append(i)\n",
    "#             print(len(switchingindices))\n",
    "#             print(switchingindices)\n",
    "        # if value is within +- consecnolaugh steps from another value, we remove both values (separately) from list\n",
    "        smoothindices = []\n",
    "        for i, value in enumerate(switchingindices):\n",
    "            # need to handle 0 and last index separately so i + 1 and i - 1 will always exist below\n",
    "            if i == 0:\n",
    "                smoothindices.append(value)\n",
    "            # need to handle 0 and last index separately so i + 1 and i - 1 will always exist below\n",
    "            elif i == len(switchingindices) - 1:\n",
    "                smoothindices.append(value)\n",
    "            # this means it represents beginning of laugh, so we check end of last laugh to see how far away that was\n",
    "            elif i % 2 == 0:\n",
    "                if value - switchingindices[i - 1] > consecnolaugh:\n",
    "                    smoothindices.append(value)\n",
    "            # this means it represents end of laugh, so we check beginning of next laugh to see how far apart that is\n",
    "            elif i % 2 != 0:\n",
    "                if abs(value - switchingindices[i + 1]) > consecnolaugh:\n",
    "                    smoothindices.append(value)\n",
    "        # We should have pairs at this point so number of indices shoud be even (thus divisible by 2 evenly)\n",
    "        if len(smoothindices) % 2 != 0:\n",
    "            print(\"WE HAVE AN ERROR\")\n",
    "            break\n",
    "#             print(len(smoothindices))\n",
    "#             print(smoothindices)\n",
    "        # combining the pairs into their own sublists now\n",
    "        coupledlist = []\n",
    "        templist = []\n",
    "        for i, timestep in enumerate(smoothindices):\n",
    "            if i % 2 == 0:\n",
    "                templist.append(timestep)\n",
    "            if i % 2 != 0:\n",
    "                templist.append(timestep)\n",
    "                coupledlist.append(templist)\n",
    "                templist = []\n",
    "#             print(len(coupledlist))\n",
    "#             print(coupledlist)\n",
    "        # removing all laughter that is deemed too short in length\n",
    "        minlaughlist = [pair for pair in coupledlist if pair[1] - pair[0] >= consecsteps]\n",
    "#             print(len(minlaughlist))\n",
    "#             print(minlaughlist)\n",
    "        # translating from timesteps into ms\n",
    "        laughranges = []\n",
    "        for pair in minlaughlist:\n",
    "            templist = [int(step * timesteplen) for step in pair]\n",
    "            laughranges.append(templist)\n",
    "#             print(len(laughranges))\n",
    "#             print(laughranges)\n",
    "        laughrangesdict[season + episode] = laughranges\n",
    "print(len(laughrangesdict.keys()))\n",
    "print(laughrangesdict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new SQLite table to store laughter instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connecting to friendsdb SQLite database and creating laughs table\n",
    "conn = sqlite3.connect('/Users/Jack/Developer/friends/friendsdb.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.executescript('''\n",
    "CREATE TABLE IF NOT EXISTS laughs (\n",
    "    id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    season INTEGER,\n",
    "    episode INTEGER,\n",
    "    beg INTEGER,\n",
    "    end TEXT,\n",
    "    UNIQUE(season, episode, beg)\n",
    ");\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputting laughter instances\n",
    "\n",
    "We take our nicely formatted laughter ranges, organized by episode, and we store them in a SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seasep, eplaughs in laughrangesdict.items():\n",
    "    season = int(seasep[0:2])\n",
    "    episode = int(seasep[2:4])\n",
    "    for laugh in eplaughs:\n",
    "        beg = laugh[0]\n",
    "        end = laugh[1]\n",
    "        cur.execute('''INSERT OR REPLACE INTO laughs (season, episode, beg, end)\n",
    "            VALUES ( ?, ?, ?, ? )''', ( season, episode, beg, end ) )\n",
    "        conn.commit()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding column to laughs table in SQLite so we can attribute the laugh to a character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addColumn = \"ALTER TABLE laughs ADD COLUMN char TEXT\"\n",
    "\n",
    "cur.execute(addColumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
